{
  "models": [
    {"id": "gpt-4.1", "name": "GPT-4.1", "vendor": "Azure OpenAI", "family": "gpt-4.1", "supported_endpoints": [], "max_context_window_tokens": 128000, "max_output_tokens": 16384, "max_prompt_tokens": 128000},
    {"id": "gpt-5-mini", "name": "GPT-5 mini", "vendor": "Azure OpenAI", "family": "gpt-5-mini", "supported_endpoints": [], "max_context_window_tokens": 264000, "max_output_tokens": 64000, "max_prompt_tokens": 128000},
    {"id": "gpt-5", "name": "GPT-5", "vendor": "Azure OpenAI", "family": "gpt-5", "supported_endpoints": ["/chat/completions", "/responses"], "max_context_window_tokens": 400000, "max_output_tokens": 128000, "max_prompt_tokens": 128000},
    {"id": "gpt-3.5-turbo", "name": "GPT 3.5 Turbo", "vendor": "Azure OpenAI", "family": "gpt-3.5-turbo", "supported_endpoints": [], "max_context_window_tokens": 16384, "max_output_tokens": 4096, "max_prompt_tokens": 16384},
    {"id": "gpt-3.5-turbo-0613", "name": "GPT 3.5 Turbo", "vendor": "Azure OpenAI", "family": "gpt-3.5-turbo", "supported_endpoints": [], "max_context_window_tokens": 16384, "max_output_tokens": 4096, "max_prompt_tokens": 16384},
    {"id": "gpt-4o-mini", "name": "GPT-4o mini", "vendor": "Azure OpenAI", "family": "gpt-4o-mini", "supported_endpoints": [], "max_context_window_tokens": 128000, "max_output_tokens": 4096, "max_prompt_tokens": 64000},
    {"id": "gpt-4o-mini-2024-07-18", "name": "GPT-4o mini", "vendor": "Azure OpenAI", "family": "gpt-4o-mini", "supported_endpoints": [], "max_context_window_tokens": 128000, "max_output_tokens": 4096, "max_prompt_tokens": 64000},
    {"id": "gpt-4", "name": "GPT 4", "vendor": "Azure OpenAI", "family": "gpt-4", "supported_endpoints": [], "max_context_window_tokens": 32768, "max_output_tokens": 4096, "max_prompt_tokens": 32768},
    {"id": "gpt-4-0613", "name": "GPT 4", "vendor": "Azure OpenAI", "family": "gpt-4", "supported_endpoints": [], "max_context_window_tokens": 32768, "max_output_tokens": 4096, "max_prompt_tokens": 32768},
    {"id": "gpt-4o", "name": "GPT-4o", "vendor": "Azure OpenAI", "family": "gpt-4o", "supported_endpoints": [], "max_context_window_tokens": 128000, "max_output_tokens": 4096, "max_prompt_tokens": 64000},
    {"id": "gpt-4o-2024-11-20", "name": "GPT-4o", "vendor": "Azure OpenAI", "family": "gpt-4o", "supported_endpoints": [], "max_context_window_tokens": 128000, "max_output_tokens": 16384, "max_prompt_tokens": 64000},
    {"id": "gpt-4o-2024-05-13", "name": "GPT-4o", "vendor": "Azure OpenAI", "family": "gpt-4o", "supported_endpoints": [], "max_context_window_tokens": 128000, "max_output_tokens": 4096, "max_prompt_tokens": 64000},
    {"id": "gpt-4-o-preview", "name": "GPT-4o", "vendor": "Azure OpenAI", "family": "gpt-4o", "supported_endpoints": [], "max_context_window_tokens": 128000, "max_output_tokens": 4096, "max_prompt_tokens": 64000},
    {"id": "gpt-4o-2024-08-06", "name": "GPT-4o", "vendor": "Azure OpenAI", "family": "gpt-4o", "supported_endpoints": [], "max_context_window_tokens": 128000, "max_output_tokens": 16384, "max_prompt_tokens": 64000},
    {"id": "gpt-41-copilot", "name": "GPT-4.1 Copilot", "vendor": "Azure OpenAI", "family": "gpt-4.1", "supported_endpoints": [], "max_context_window_tokens": null, "max_output_tokens": null, "max_prompt_tokens": null},
    {"id": "gpt-5.1", "name": "GPT-5.1", "vendor": "OpenAI", "family": "gpt-5.1", "supported_endpoints": ["/chat/completions", "/responses"], "max_context_window_tokens": 264000, "max_output_tokens": 64000, "max_prompt_tokens": 128000},
    {"id": "text-embedding-ada-002", "name": "Embedding V2 Ada", "vendor": "Azure OpenAI", "family": "text-embedding-ada-002", "supported_endpoints": [], "max_context_window_tokens": null, "max_output_tokens": null, "max_prompt_tokens": null, "max_inputs": 512},
    {"id": "text-embedding-3-small", "name": "Embedding V3 small", "vendor": "Azure OpenAI", "family": "text-embedding-3-small", "supported_endpoints": [], "max_context_window_tokens": null, "max_output_tokens": null, "max_prompt_tokens": null, "max_inputs": 512},
    {"id": "text-embedding-3-small-inference", "name": "Embedding V3 small (Inference)", "vendor": "Azure OpenAI", "family": "text-embedding-3-small", "supported_endpoints": [], "max_context_window_tokens": null, "max_output_tokens": null, "max_prompt_tokens": null},
    {"id": "claude-sonnet-4", "name": "Claude Sonnet 4", "vendor": "Anthropic", "family": "claude-sonnet-4", "supported_endpoints": ["/chat/completions"], "max_context_window_tokens": 216000, "max_output_tokens": 16000, "max_prompt_tokens": 128000},
    {"id": "claude-sonnet-4.5", "name": "Claude Sonnet 4.5", "vendor": "Anthropic", "family": "claude-sonnet-4.5", "supported_endpoints": ["/chat/completions"], "max_context_window_tokens": 144000, "max_output_tokens": 16000, "max_prompt_tokens": 128000},
    {"id": "claude-opus-4.5", "name": "Claude Opus 4.5 (Preview)", "vendor": "Anthropic", "family": "claude-opus-4.5", "supported_endpoints": [], "max_context_window_tokens": 144000, "max_output_tokens": 16000, "max_prompt_tokens": 128000},
    {"id": "claude-opus-41", "name": "Claude Opus 4.1", "vendor": "Anthropic", "family": "claude-opus-4.1", "supported_endpoints": ["/chat/completions"], "max_context_window_tokens": 80000, "max_output_tokens": 16000, "max_prompt_tokens": 80000},
    {"id": "claude-haiku-4.5", "name": "Claude Haiku 4.5", "vendor": "Anthropic", "family": "claude-haiku-4.5", "supported_endpoints": ["/chat/completions"], "max_context_window_tokens": 144000, "max_output_tokens": 16000, "max_prompt_tokens": 128000},
    {"id": "gemini-3-pro-preview", "name": "Gemini 3 Pro (Preview)", "vendor": "Google", "family": "gemini-3-pro", "supported_endpoints": [], "max_context_window_tokens": 128000, "max_output_tokens": 64000, "max_prompt_tokens": 128000},
    {"id": "gemini-2.5-pro", "name": "Gemini 2.5 Pro", "vendor": "Google", "family": "gemini-2.5-pro", "supported_endpoints": [], "max_context_window_tokens": 128000, "max_output_tokens": 64000, "max_prompt_tokens": 128000},
    {"id": "gpt-4.1-2025-04-14", "name": "GPT-4.1", "vendor": "Azure OpenAI", "family": "gpt-4.1", "supported_endpoints": [], "max_context_window_tokens": 128000, "max_output_tokens": 16384, "max_prompt_tokens": 128000}
  ]
}